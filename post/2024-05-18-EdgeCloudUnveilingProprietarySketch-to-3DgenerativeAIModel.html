<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>엣지클라우드 독자적인 스케치로 3D 모델 생성하는 AI 모델 공개 | blocktong</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://blocktong.github.io///post/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="엣지클라우드 독자적인 스케치로 3D 모델 생성하는 AI 모델 공개 | blocktong" data-gatsby-head="true"/><meta property="og:title" content="엣지클라우드 독자적인 스케치로 3D 모델 생성하는 AI 모델 공개 | blocktong" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://blocktong.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://blocktong.github.io///post/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel" data-gatsby-head="true"/><meta name="twitter:title" content="엣지클라우드 독자적인 스케치로 3D 모델 생성하는 AI 모델 공개 | blocktong" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | blocktong" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-18 00:40" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-5b12619e815e966a.js" defer=""></script><script src="/_next/static/z0ZGRQY04MD5cUdT-Nqp1/_buildManifest.js" defer=""></script><script src="/_next/static/z0ZGRQY04MD5cUdT-Nqp1/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Block Tong</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">엣지클라우드 독자적인 스케치로 3D 모델 생성하는 AI 모델 공개</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="엣지클라우드 독자적인 스케치로 3D 모델 생성하는 AI 모델 공개" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">Block Tong</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 18, 2024</span><span class="posts_reading_time__f7YPP">5<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p><img src="/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_0.png" alt="EdgeCloud Unveiling Sketch-to-3D Generative AI Model"></p>
<p>안녕하세요! Theta 팀에서는 2024년 5월 15일 AMA 중에 CTO Jieyi가 데모를 선보인 Sketch-to-3D generative AI 모델에 대한 자세한 내용을 곧 공유할 예정입니다. 녹화 영상은 여기서 확인하실 수 있어요. 이 모델의 AI 기술은 정말 혁신적이며 놀랍게 복잡합니다. 이 사유적인 AI 모형 파이프라인은 지난 해 대부분 Theta에서 개발되었습니다. 저희는 기쁘게 알려드립니다. EdgeCloud의 프로덕션 환경에 배포되었다는 사실을:</p>
<p><a href="https://www.ThetaEdgeCloud.com/dashboard/ai/service/model-explorer" rel="nofollow" target="_blank">Theta EdgeCloud AI Service Model Explorer</a></p>
<h1>도전적인 generative AI 문제</h1>
<div class="content-ad"></div>
<p>스케치를 3D로 변환하는 작업은 선과 모양을 해석하여 손으로 그린 스케치를 정확하게 3D 디지털 객체로 변환하는 매우 어려운 생성적 AI 작업입니다. 이 기술은 영화 애니메이션, 게임부터 건축 및 산업 디자인까지 다양한 분야에서 활용될 수 있으며, 예술가와 디자이너들이 아이디어를 빠르게 프로토타입화하고 개념을 완전히 상호작용 3D 공간에서 시각화하는 데 도움이 됩니다.</p>
<p>간단하고 종종 거친 2D 스케치를 상세하고 정확한 3D 모델로 변환하는 작업은 예술가가 2D 스케치에서 가상으로 그리는 섬세한 세부 사항과 모양을 보존한 고 공간 해상도의 3D 모델을 생성하는 것이 어려운 점이 많습니다.</p>
<p>우리는 이 작업을 두 단계로 나눠 처리합니다. 먼저 스케치를 "2.5D" 이미지로 변환하고, 이는 3D 개체를 2D 평면에 투영한 것입니다. 그리고 이러한 투영 이미지를 3D 모델로 변환합니다. 이 두 단계 접근법은 작년 GoogleCloud Next 컨퍼런스에서 Theta Labs와 GoogleCloud가 공동으로 발표한 "모델-파이프라인" 개념의 또 다른 예시입니다.</p>
<h1>단계 1 — 스케치를 3D 모델로 변환하는 파이프라인 디자인</h1>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_1.png" alt="EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_1.png"></p>
<p>우리의 첫 번째 단계는 스케치로부터 2.5차원 이미지를 생성하는 것인데, 이는 StableDiffusion과 ControlNet의 강력한 조합을 사용합니다. 특히, 우리는 고급 신경망 구조인 ControlNet을 통합했습니다. ControlNet은 확산 모델을 사용한 이미지 합성의 맥락에서 모델 생성 과정 중에 추가적인 제어와 정밀도를 제공하도록 설계된 신경망입니다. ControlNet은 이러한 모델들의 기능을 향상시킴으로써 추가 조건이나 제약 조건을 통합하여 출력물을 보다 효과적으로 가이드할 수 있습니다. 이는 스케치를 2.5차원 이미지로 변환하는 응용 프로그램과 같이 원본 스케치의 무결성과 세부 정보를 유지하는 데 중요합니다. 우리는 ReV Animated 모델을 재교육하여 상세한 2.5차원 이미지를 생성하는 능력 때문에 Stable Diffusion을 선택했습니다. 이 접근 방식은 3D 모델링 작업에 견고한 기반을 확립했습니다.</p>
<p><img src="/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_2.png" alt="EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_2.png"></p>
<h1>Stage 2 — 스케치에서 3D 모델로의 파이프라인 디자인</h1>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_3.png" alt="EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_3"></p>
<p>이제 두 번째 단계인 2.5D 이미지를 3D 모델로 변환하는 과정이 시작됩니다. 이 프로세스는 고급 객체 추출 알고리즘을 사용하여 2.5D 이미지에서 주요 객체를 추출하여 배경 소음과 간섭을 효과적으로 줄이는 것으로 시작됩니다. 이 단계는 주요 객체가 정확하게 분리되도록 정밀하고 세심한 주의가 필요합니다. 이후 TripoSR을 활용하여 3D 모델을 구성했습니다. TripoSR은 Stability.ai에서 개발된 모델로, 자세하고 정확한 3D 표현에 뛰어납니다. 이 첨단 기술의 조합은 간단한 스케치를 효율적이고 정확하게 세밀한 3D 모델로 변환하는 복잡하면서도 매우 효과적인 워크플로를 만들어 냅니다.</p>
<h1>대규모 제품 배포 모델</h1>
<p>Theta의 독점적인 Sketch-to-3D 모델은 이제 Theta EdgeCloud 대시보드에서 사용 가능합니다:</p>
<div class="content-ad"></div>
<p><a href="https://www.ThetaEdgeCloud.com/dashboard/ai/service/model-explorer" rel="nofollow" target="_blank">https://www.ThetaEdgeCloud.com/dashboard/ai/service/model-explorer</a></p>
<p><img src="/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_4.png" alt="EdgeCloud Unveiling Sketch-to-3D generative AI Model"></p>
<p>여기서 몇 번의 클릭만으로 모델을 실행할 수 있습니다. 모델이 EdgeCloud에 성공적으로 배포되면 <a href="https://sketchtoxxxxx.tec-s1.onthetaedgecloud.com/%EC%99%80" rel="nofollow" target="_blank">https://sketchtoxxxxx.tec-s1.onthetaedgecloud.com/와</a> 같은 추론 엔드포인트를 얻을 수 있습니다. 해당 엔드포인트를 클릭하면 WebUI가 표시되고, 여기서는 스케치 이미지를 업로드하거나 직접 그림판에 스케치할 수 있습니다. 스케치를 업로드한 후, 생성하고자 하는 3D 개체를 설명하는 텍스트 프롬프트를 제공할 수 있습니다. 그런 다음 "2D 생성" 버튼을 클릭하세요. 만족스러운 2.5D 이미지가 생성될 때까지 몇 번 시도할 수 있습니다. 그런 다음 "3D 생성" 버튼을 클릭하여 3D 모델로 변환하세요! 생성된 3D 모델은 WebUI에서 확대 및 회전할 수 있습니다. 또한 모델을 다운로드하여 다른 3D 모델링 도구로 가져올 수 있습니다. 첫 번째 생성에는 모델 매개변수를로드해야 하므로 약 2-3분이 소요될 수 있지만 두 번째 생성부터는 더 빨라질 것입니다.</p>
<p><img src="/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_5.png" alt="EdgeCloud Unveiling Sketch-to-3D generative AI Model"></p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_6.png" alt="Gradio WebUI and API endpoint documentation"></p>
<p><strong>그림 5. Theta EdgeCloud에서 실행 중인 Sketch-to-3D 모델의 Gradio WebUI 및 API 엔드포인트 문서</strong></p>
<p>이 모델은 개발자들이 프로그래밍 방식으로 스케치에서 3D 생성을 수행하거나 이 기능을 사용자 정의 애플리케이션에 통합할 수 있도록 하는 API 세트를 제공합니다. API 엔드포인트 및 문서를 보려면 WebUI 하단의 "API를 통해 사용" 버튼을 클릭하거나 추론 엔드포인트에 <code>?view=api</code>를 추가하십시오. 예를 들어, <a href="https://sketchtoxxxxx.tec-s1.onthetaedgecloud.com/?view=api%EC%99%80" rel="nofollow" target="_blank">https://sketchtoxxxxx.tec-s1.onthetaedgecloud.com/?view=api와</a> 같습니다.</p>
<p>우리는 곧 AI 쇼케이스에 스케치에서 3D 생성을 추가할 예정이니 기대해 주세요. 한편, Theta의 독점 3D GenAI를 즐기세요! 🌟</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"엣지클라우드 독자적인 스케치로 3D 모델 생성하는 AI 모델 공개","description":"","date":"2024-05-18 00:40","slug":"2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel","content":"\n\n![EdgeCloud Unveiling Sketch-to-3D Generative AI Model](/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_0.png)\n\n안녕하세요! Theta 팀에서는 2024년 5월 15일 AMA 중에 CTO Jieyi가 데모를 선보인 Sketch-to-3D generative AI 모델에 대한 자세한 내용을 곧 공유할 예정입니다. 녹화 영상은 여기서 확인하실 수 있어요. 이 모델의 AI 기술은 정말 혁신적이며 놀랍게 복잡합니다. 이 사유적인 AI 모형 파이프라인은 지난 해 대부분 Theta에서 개발되었습니다. 저희는 기쁘게 알려드립니다. EdgeCloud의 프로덕션 환경에 배포되었다는 사실을:\n\n[Theta EdgeCloud AI Service Model Explorer](https://www.ThetaEdgeCloud.com/dashboard/ai/service/model-explorer)\n\n# 도전적인 generative AI 문제\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n스케치를 3D로 변환하는 작업은 선과 모양을 해석하여 손으로 그린 스케치를 정확하게 3D 디지털 객체로 변환하는 매우 어려운 생성적 AI 작업입니다. 이 기술은 영화 애니메이션, 게임부터 건축 및 산업 디자인까지 다양한 분야에서 활용될 수 있으며, 예술가와 디자이너들이 아이디어를 빠르게 프로토타입화하고 개념을 완전히 상호작용 3D 공간에서 시각화하는 데 도움이 됩니다.\n\n간단하고 종종 거친 2D 스케치를 상세하고 정확한 3D 모델로 변환하는 작업은 예술가가 2D 스케치에서 가상으로 그리는 섬세한 세부 사항과 모양을 보존한 고 공간 해상도의 3D 모델을 생성하는 것이 어려운 점이 많습니다.\n\n우리는 이 작업을 두 단계로 나눠 처리합니다. 먼저 스케치를 \"2.5D\" 이미지로 변환하고, 이는 3D 개체를 2D 평면에 투영한 것입니다. 그리고 이러한 투영 이미지를 3D 모델로 변환합니다. 이 두 단계 접근법은 작년 GoogleCloud Next 컨퍼런스에서 Theta Labs와 GoogleCloud가 공동으로 발표한 \"모델-파이프라인\" 개념의 또 다른 예시입니다.\n\n# 단계 1 — 스케치를 3D 모델로 변환하는 파이프라인 디자인\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_1.png](/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_1.png)\n\n우리의 첫 번째 단계는 스케치로부터 2.5차원 이미지를 생성하는 것인데, 이는 StableDiffusion과 ControlNet의 강력한 조합을 사용합니다. 특히, 우리는 고급 신경망 구조인 ControlNet을 통합했습니다. ControlNet은 확산 모델을 사용한 이미지 합성의 맥락에서 모델 생성 과정 중에 추가적인 제어와 정밀도를 제공하도록 설계된 신경망입니다. ControlNet은 이러한 모델들의 기능을 향상시킴으로써 추가 조건이나 제약 조건을 통합하여 출력물을 보다 효과적으로 가이드할 수 있습니다. 이는 스케치를 2.5차원 이미지로 변환하는 응용 프로그램과 같이 원본 스케치의 무결성과 세부 정보를 유지하는 데 중요합니다. 우리는 ReV Animated 모델을 재교육하여 상세한 2.5차원 이미지를 생성하는 능력 때문에 Stable Diffusion을 선택했습니다. 이 접근 방식은 3D 모델링 작업에 견고한 기반을 확립했습니다.\n\n![EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_2.png](/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_2.png)\n\n# Stage 2 — 스케치에서 3D 모델로의 파이프라인 디자인\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_3](/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_3.png)\n\n이제 두 번째 단계인 2.5D 이미지를 3D 모델로 변환하는 과정이 시작됩니다. 이 프로세스는 고급 객체 추출 알고리즘을 사용하여 2.5D 이미지에서 주요 객체를 추출하여 배경 소음과 간섭을 효과적으로 줄이는 것으로 시작됩니다. 이 단계는 주요 객체가 정확하게 분리되도록 정밀하고 세심한 주의가 필요합니다. 이후 TripoSR을 활용하여 3D 모델을 구성했습니다. TripoSR은 Stability.ai에서 개발된 모델로, 자세하고 정확한 3D 표현에 뛰어납니다. 이 첨단 기술의 조합은 간단한 스케치를 효율적이고 정확하게 세밀한 3D 모델로 변환하는 복잡하면서도 매우 효과적인 워크플로를 만들어 냅니다.\n\n# 대규모 제품 배포 모델\n\nTheta의 독점적인 Sketch-to-3D 모델은 이제 Theta EdgeCloud 대시보드에서 사용 가능합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttps://www.ThetaEdgeCloud.com/dashboard/ai/service/model-explorer\n\n![EdgeCloud Unveiling Sketch-to-3D generative AI Model](/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_4.png)\n\n여기서 몇 번의 클릭만으로 모델을 실행할 수 있습니다. 모델이 EdgeCloud에 성공적으로 배포되면 https://sketchtoxxxxx.tec-s1.onthetaedgecloud.com/와 같은 추론 엔드포인트를 얻을 수 있습니다. 해당 엔드포인트를 클릭하면 WebUI가 표시되고, 여기서는 스케치 이미지를 업로드하거나 직접 그림판에 스케치할 수 있습니다. 스케치를 업로드한 후, 생성하고자 하는 3D 개체를 설명하는 텍스트 프롬프트를 제공할 수 있습니다. 그런 다음 \"2D 생성\" 버튼을 클릭하세요. 만족스러운 2.5D 이미지가 생성될 때까지 몇 번 시도할 수 있습니다. 그런 다음 \"3D 생성\" 버튼을 클릭하여 3D 모델로 변환하세요! 생성된 3D 모델은 WebUI에서 확대 및 회전할 수 있습니다. 또한 모델을 다운로드하여 다른 3D 모델링 도구로 가져올 수 있습니다. 첫 번째 생성에는 모델 매개변수를로드해야 하므로 약 2-3분이 소요될 수 있지만 두 번째 생성부터는 더 빨라질 것입니다.\n\n![EdgeCloud Unveiling Sketch-to-3D generative AI Model](/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Gradio WebUI and API endpoint documentation](/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_6.png)\n\n**그림 5. Theta EdgeCloud에서 실행 중인 Sketch-to-3D 모델의 Gradio WebUI 및 API 엔드포인트 문서**\n\n이 모델은 개발자들이 프로그래밍 방식으로 스케치에서 3D 생성을 수행하거나 이 기능을 사용자 정의 애플리케이션에 통합할 수 있도록 하는 API 세트를 제공합니다. API 엔드포인트 및 문서를 보려면 WebUI 하단의 \"API를 통해 사용\" 버튼을 클릭하거나 추론 엔드포인트에 `?view=api`를 추가하십시오. 예를 들어, https://sketchtoxxxxx.tec-s1.onthetaedgecloud.com/?view=api와 같습니다.\n\n우리는 곧 AI 쇼케이스에 스케치에서 3D 생성을 추가할 예정이니 기대해 주세요. 한편, Theta의 독점 3D GenAI를 즐기세요! 🌟","ogImage":{"url":"/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_0.png"},"coverImage":"/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_0.png","tag":["Tech"],"readingTime":5},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_0.png\" alt=\"EdgeCloud Unveiling Sketch-to-3D Generative AI Model\"\u003e\u003c/p\u003e\n\u003cp\u003e안녕하세요! Theta 팀에서는 2024년 5월 15일 AMA 중에 CTO Jieyi가 데모를 선보인 Sketch-to-3D generative AI 모델에 대한 자세한 내용을 곧 공유할 예정입니다. 녹화 영상은 여기서 확인하실 수 있어요. 이 모델의 AI 기술은 정말 혁신적이며 놀랍게 복잡합니다. 이 사유적인 AI 모형 파이프라인은 지난 해 대부분 Theta에서 개발되었습니다. 저희는 기쁘게 알려드립니다. EdgeCloud의 프로덕션 환경에 배포되었다는 사실을:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.ThetaEdgeCloud.com/dashboard/ai/service/model-explorer\" rel=\"nofollow\" target=\"_blank\"\u003eTheta EdgeCloud AI Service Model Explorer\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e도전적인 generative AI 문제\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e스케치를 3D로 변환하는 작업은 선과 모양을 해석하여 손으로 그린 스케치를 정확하게 3D 디지털 객체로 변환하는 매우 어려운 생성적 AI 작업입니다. 이 기술은 영화 애니메이션, 게임부터 건축 및 산업 디자인까지 다양한 분야에서 활용될 수 있으며, 예술가와 디자이너들이 아이디어를 빠르게 프로토타입화하고 개념을 완전히 상호작용 3D 공간에서 시각화하는 데 도움이 됩니다.\u003c/p\u003e\n\u003cp\u003e간단하고 종종 거친 2D 스케치를 상세하고 정확한 3D 모델로 변환하는 작업은 예술가가 2D 스케치에서 가상으로 그리는 섬세한 세부 사항과 모양을 보존한 고 공간 해상도의 3D 모델을 생성하는 것이 어려운 점이 많습니다.\u003c/p\u003e\n\u003cp\u003e우리는 이 작업을 두 단계로 나눠 처리합니다. 먼저 스케치를 \"2.5D\" 이미지로 변환하고, 이는 3D 개체를 2D 평면에 투영한 것입니다. 그리고 이러한 투영 이미지를 3D 모델로 변환합니다. 이 두 단계 접근법은 작년 GoogleCloud Next 컨퍼런스에서 Theta Labs와 GoogleCloud가 공동으로 발표한 \"모델-파이프라인\" 개념의 또 다른 예시입니다.\u003c/p\u003e\n\u003ch1\u003e단계 1 — 스케치를 3D 모델로 변환하는 파이프라인 디자인\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_1.png\" alt=\"EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e우리의 첫 번째 단계는 스케치로부터 2.5차원 이미지를 생성하는 것인데, 이는 StableDiffusion과 ControlNet의 강력한 조합을 사용합니다. 특히, 우리는 고급 신경망 구조인 ControlNet을 통합했습니다. ControlNet은 확산 모델을 사용한 이미지 합성의 맥락에서 모델 생성 과정 중에 추가적인 제어와 정밀도를 제공하도록 설계된 신경망입니다. ControlNet은 이러한 모델들의 기능을 향상시킴으로써 추가 조건이나 제약 조건을 통합하여 출력물을 보다 효과적으로 가이드할 수 있습니다. 이는 스케치를 2.5차원 이미지로 변환하는 응용 프로그램과 같이 원본 스케치의 무결성과 세부 정보를 유지하는 데 중요합니다. 우리는 ReV Animated 모델을 재교육하여 상세한 2.5차원 이미지를 생성하는 능력 때문에 Stable Diffusion을 선택했습니다. 이 접근 방식은 3D 모델링 작업에 견고한 기반을 확립했습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_2.png\" alt=\"EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_2.png\"\u003e\u003c/p\u003e\n\u003ch1\u003eStage 2 — 스케치에서 3D 모델로의 파이프라인 디자인\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_3.png\" alt=\"EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_3\"\u003e\u003c/p\u003e\n\u003cp\u003e이제 두 번째 단계인 2.5D 이미지를 3D 모델로 변환하는 과정이 시작됩니다. 이 프로세스는 고급 객체 추출 알고리즘을 사용하여 2.5D 이미지에서 주요 객체를 추출하여 배경 소음과 간섭을 효과적으로 줄이는 것으로 시작됩니다. 이 단계는 주요 객체가 정확하게 분리되도록 정밀하고 세심한 주의가 필요합니다. 이후 TripoSR을 활용하여 3D 모델을 구성했습니다. TripoSR은 Stability.ai에서 개발된 모델로, 자세하고 정확한 3D 표현에 뛰어납니다. 이 첨단 기술의 조합은 간단한 스케치를 효율적이고 정확하게 세밀한 3D 모델로 변환하는 복잡하면서도 매우 효과적인 워크플로를 만들어 냅니다.\u003c/p\u003e\n\u003ch1\u003e대규모 제품 배포 모델\u003c/h1\u003e\n\u003cp\u003eTheta의 독점적인 Sketch-to-3D 모델은 이제 Theta EdgeCloud 대시보드에서 사용 가능합니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://www.ThetaEdgeCloud.com/dashboard/ai/service/model-explorer\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://www.ThetaEdgeCloud.com/dashboard/ai/service/model-explorer\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_4.png\" alt=\"EdgeCloud Unveiling Sketch-to-3D generative AI Model\"\u003e\u003c/p\u003e\n\u003cp\u003e여기서 몇 번의 클릭만으로 모델을 실행할 수 있습니다. 모델이 EdgeCloud에 성공적으로 배포되면 \u003ca href=\"https://sketchtoxxxxx.tec-s1.onthetaedgecloud.com/%EC%99%80\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://sketchtoxxxxx.tec-s1.onthetaedgecloud.com/와\u003c/a\u003e 같은 추론 엔드포인트를 얻을 수 있습니다. 해당 엔드포인트를 클릭하면 WebUI가 표시되고, 여기서는 스케치 이미지를 업로드하거나 직접 그림판에 스케치할 수 있습니다. 스케치를 업로드한 후, 생성하고자 하는 3D 개체를 설명하는 텍스트 프롬프트를 제공할 수 있습니다. 그런 다음 \"2D 생성\" 버튼을 클릭하세요. 만족스러운 2.5D 이미지가 생성될 때까지 몇 번 시도할 수 있습니다. 그런 다음 \"3D 생성\" 버튼을 클릭하여 3D 모델로 변환하세요! 생성된 3D 모델은 WebUI에서 확대 및 회전할 수 있습니다. 또한 모델을 다운로드하여 다른 3D 모델링 도구로 가져올 수 있습니다. 첫 번째 생성에는 모델 매개변수를로드해야 하므로 약 2-3분이 소요될 수 있지만 두 번째 생성부터는 더 빨라질 것입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_5.png\" alt=\"EdgeCloud Unveiling Sketch-to-3D generative AI Model\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel_6.png\" alt=\"Gradio WebUI and API endpoint documentation\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e그림 5. Theta EdgeCloud에서 실행 중인 Sketch-to-3D 모델의 Gradio WebUI 및 API 엔드포인트 문서\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e이 모델은 개발자들이 프로그래밍 방식으로 스케치에서 3D 생성을 수행하거나 이 기능을 사용자 정의 애플리케이션에 통합할 수 있도록 하는 API 세트를 제공합니다. API 엔드포인트 및 문서를 보려면 WebUI 하단의 \"API를 통해 사용\" 버튼을 클릭하거나 추론 엔드포인트에 \u003ccode\u003e?view=api\u003c/code\u003e를 추가하십시오. 예를 들어, \u003ca href=\"https://sketchtoxxxxx.tec-s1.onthetaedgecloud.com/?view=api%EC%99%80\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://sketchtoxxxxx.tec-s1.onthetaedgecloud.com/?view=api와\u003c/a\u003e 같습니다.\u003c/p\u003e\n\u003cp\u003e우리는 곧 AI 쇼케이스에 스케치에서 3D 생성을 추가할 예정이니 기대해 주세요. 한편, Theta의 독점 3D GenAI를 즐기세요! 🌟\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-18-EdgeCloudUnveilingProprietarySketch-to-3DgenerativeAIModel"},"buildId":"z0ZGRQY04MD5cUdT-Nqp1","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>