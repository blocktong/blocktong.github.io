<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>신뢰하지 말고 검증하세요 탈중앙화 추론 개요 | blocktong</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://blocktong.github.io///post/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="신뢰하지 말고 검증하세요 탈중앙화 추론 개요 | blocktong" data-gatsby-head="true"/><meta property="og:title" content="신뢰하지 말고 검증하세요 탈중앙화 추론 개요 | blocktong" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://blocktong.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://blocktong.github.io///post/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference" data-gatsby-head="true"/><meta name="twitter:title" content="신뢰하지 말고 검증하세요 탈중앙화 추론 개요 | blocktong" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | blocktong" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-05 16:28" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V5DKFTZ6BX"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-V5DKFTZ6BX');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-46e6ca0ca48de91b.js" defer=""></script><script src="/_next/static/o88Ur64-oLrud7YPysgph/_buildManifest.js" defer=""></script><script src="/_next/static/o88Ur64-oLrud7YPysgph/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Block Tong</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">신뢰하지 말고 검증하세요 탈중앙화 추론 개요</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="신뢰하지 말고 검증하세요 탈중앙화 추론 개요" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">Block Tong</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 5, 2024</span><span class="posts_reading_time__f7YPP">7<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><p>Llama2-70B와 같은 대규모 언어 모델을 실행하려고 한다고 가정해 봅시다. 이 정도 규모의 모델을 실행하려면 140GB 이상의 메모리가 필요합니다. 이는 집에 있는 컴퓨터에서 원시 모델을 실행할 수 없다는 것을 의미합니다. 그렇다면 옵션은 무엇일까요? 클라우드 제공업체로 이동할 수 있지만, 이 작업 부하를 처리하고 사용 데이터를 모아가는 단일 중앙화된 회사에 너무 의존하기를 원치 않을 수도 있습니다. 그럴 때 필요한 것은 분산 추론(decentralized inference)입니다. 이것을 통해 단일 공급업체에 의존하지 않고 ML 모델을 실행할 수 있습니다.</p>
<h2>신뢰 문제</h2>
<p>분산 네트워크에서 모델을 실행하고 출력을 신뢰한다는 것만으로는 충분하지 않습니다. 예를 들어 네트워크에게 Llama2-70B를 사용하여 거버넌스 딜레마를 분석해 달라고 요청했다고 가정해 봅시다. 어떻게 알 수 있을까요? 실제로 Llama2-13B를 사용하여 더 나쁜 분석을 제공하고 그 차이를 얻고 있는 것은 아닌지요?</p>
<p>중앙화된 세계에서는 OpenAI와 같은 기업들이 실질적인 미션 수행 때문에 정직하게 일처리를 한다고 믿을지도 모릅니다(그리고 어느 정도로는 LLM 품질이 명백합니다). 그러나 분산화된 세계에서는 정직함이 가정되지 않습니다 — 검증되어야 합니다.</p>
<p>이곳이 검증 가능 추론의 중요성이 드러나는 곳입니다. 질문에 대한 응답을 제공하는 것뿐만 아니라 요청한 모델에서 정확히 실행되었음을 증명해야 합니다. 하지만 어떻게 할까요?</p>
<p>소박한 방식은 모델을 스마트 계약으로 체인 상에서 실행하는 것일 것입니다. 이렇게 하면 출력이 검증되었음이 보장될 것입니다. 하지만 이는 현실적으로 매우 어렵습니다. GPT-3는 12,288 차원의 임베딩으로 단어를 표현합니다. 이 크기의 단일 행렬 곱셈을 체인 상에서 수행하려면, 현재의 가스 가격에서는 약 100억 달러가 들 것입니다. 계산이 각 블록을 한 달 동안 가득 채울 것입니다.</p>
<p>그러므로, 아닙니다. 우리는 다른 방법이 필요할 것입니다.</p>
<p>현 상황을 분석한 결과, 검증 가능 추론을 다루기 위해 등장한 세 가지 주요 방법이 있다는 것이 분명합니다: 제로 지식 증명, 낙관적 사기 증명, 그리고 암호경제학입니다. 각각이 강도와 비용 측면에서 독특한 특성을 지니고 있습니다.</p>
<p><img src="./assets/img/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference_0.png" alt="Zero-Knowledge Proofs (ZK ML)"/></p>
<h2>1. Zero-Knowledge Proofs (ZK ML)</h2>
<p>지금부터 상상해보세요. 여러분이 대규모 모델을 실행했다는 것을 증명할 수 있는데, 그 증명이 모델의 크기에 관계없이 고정 크기로 유효하다고 말이죠. 바로 ZK ML이 약속하는 것입니다. ZK-SNARKs의 마법 속에요.</p>
<p>이론적으로 훌륭해 보이긴 하지만, 딥 뉴럴 네트워크를 제로-지식 회로로 컴파일하고, 이를 증명할 수 있는 것은 굉장히 어려운 일이에요. 게다가 이는 엄청난 비용을 초래합니다. 최소한 추론 비용 및 생성된 증명에 드는 시간(지연)이 1000배 이상 증가할 것으로 보입니다. 여기에다가 이 모든 일이 발생하기 전에 모델 자체를 회로로 컴파일해야 하는 점도 빼놓을 수 없죠. 결과적으로 이러한 비용은 사용자에게 전가되어, 최종 사용자에게는 매우 비싸게 들어갈 것으로 예상됩니다.</p>
<p>그 반면, 이것은 암호학적으로 정확성을 보장하는 유일한 방법입니다. ZK를 사용하면, 모델 제공자가 어떻게 노력해도 속이기가 불가능합니다. 그러나 이 방법은 막대한 비용이 들어가기 때문에 장래에 거대한 모델에 대해 비실용적입니다.</p>
<p>예시: EZKL, 모듈러스 랩스, 기자</p>
<h2>2. 낙관적 사기 증명 (낙관적 ML)</h2>
<p>낙관적인 접근법은 믿음을 가지고 확인하는 것입니다. 추론이 올바르다고 가정하고, 그렇지 않음이 증명될 때까지 기다립니다. 노드가 속이려고 시도하면, 네트워크 내의 &quot;감시자&quot;들이 그를 발각하고 사기를 증명하는 증인을 동원할 수 있습니다. 이러한 감시자들은 항상 체인을 감시하고 자신의 모델에서 다시 추론을 실행하여 결과가 올바른지 확인해야 합니다.</p>
<p>이러한 사기 증명은 Truebit 스타일의 대화형 도전-응답 게임으로, 모델 실행 추적을 체인 상에서 반복적으로 이등분하여 오류를 찾을 때까지 진행됩니다.</p>
<p><img src="https://www.example.com/assets/img/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference_1.png" alt="image"/></p>
<p>이것이 실제로 발생하면 매우 비용이 많이 듭니다. 왜냐하면 이러한 프로그램은 거대하며 엄청난 내부 상태를 가지고 있기 때문입니다. 단일 GPT-3 추론 비용은 약 1 페타플롭(10의 15제곱 부동 소수점 연산)입니다. 그러나 게임 이론은 이러한 사건이 거의 발생하지 않아야 한다고 제안합니다. (사기 증명이 프로그램 코드가 실제 운영 중에 거의 절대 호출되지 않기 때문에 코드 작성이 매우 어렵습니다.)</p>
<p>이점은 낙관적인 기계 학습이 적어도 주시하는 한 사안 안전하다는 것입니다. 비용은 ZK 기계 학습보다 저렴하지만, 네트워크의 각 관찰자가 각 조회를 다시 실행하고 있다는 것을 명심하십시오. 평형상태에서, 10명의 관찰자가 있다면 해당 보안 비용은 사용자에게 전가되어야 하기 때문에 사용자는 추론 비용의 10배 이상(또는 관찰자 수에 따라 다름)을 지불해야 합니다.</p>
<p>아래로스가 놀라운 롤업들과 같이, 답변이 확인되는 데 도전 기간이 지나야 확실해진다는 단점이 있습니다. 그러나 네트워크 매개변수가 어떻게 설정되어 있는지에 따라, 몇 분만 기다리면 되는 경우도 있습니다.</p>
<p>예시: Ora, Gensyn (현재는 미상세)</p>
<h2>3. Cryptoeconomics (암호 경제학 머신러닝)</h2>
<p>여기서 우리는 모든 멋진 기술을 버리고 간단한 방법을 사용합니다: 지분 가중 투표. 사용자가 쿼리를 실행할 노드 수를 결정하고, 각 노드가 응답을 공개하고, 응답들 사이에 불일치가 있으면 이상한 것이 벌칙을 받습니다. 표준 오라클 내용이며, 사용자가 원하는 보안 수준을 설정하여 비용과 신뢰를 균형있게 조절할 수 있는 더 직접적인 접근 방식입니다. Chainlink가 머신러닝을 수행한다면 이렇게 할 것입니다.</p>
<p>여기서의 대기 시간은 빠릅니다. 각 노드에서 commit-reveal 만 있으면 됩니다. 이것이 블록체인에 기록되어야 한다면, 기술적으로 이 작업은 두 개의 블록 안에 처리될 수 있습니다.</p>
<p>하지만 보안은 가장 취약합니다. 대부분의 노드들이 마치 충분히 교묘해진다면 의도적으로 공모할 수 있습니다. 사용자로서, 여러분은 이 노드들이 얼마나 많은 것을 잃을 지, 그리고 부정행위를 한다면 그 비용이 얼마나 나갈 지에 대해 고려해야 합니다. 그럼에도 불구하고, Eigenlayer 재입금 및 연결 가능한 보안과 같은 것을 사용하면, 네트워크는 사실상 보안 실패의 경우에 보험을 제공할 수 있습니다.</p>
<p>하지만 이 시스템의 좋은 점은 사용자가 얼마나 많은 보안을 원하는지를 지정할 수 있다는 것입니다. 그들은 자신의 쿼럼에 3개 또는 5개의 노드를 선택하거나 네트워크의 모든 노드를 선택할 수 있습니다. 혹은 YOLO를 하길 원한다면, n=1을 선택할 수도 있습니다. 여기서의 비용 함수는 간단합니다: 사용자는 자신의 쿼럼에 얼마나 많은 노드를 원하는 지에 대해 지불합니다. 3개를 선택하면, 추론 비용의 3배를 지불합니다.</p>
<p>여기서의 까다로운 질문은, n=1을 안전하게 만들 수 있을까요? 단순 구현에서는, 한 개의 노드는 누가 확인하지 않는 한 항상 부정행위를 할 것입니다. 하지만 쿼리를 암호화하고 의도를 통해 지불하면, 이 작업에 대한 유일한 응답자가 실제로 자신인 것으로 노드에게 혼동을 줄 수 있을 것입니다. 이 경우, 일반 사용자들에게 평균 추론 비용의 2배 이하를 청구할 수도 있을 것입니다.</p>
<p>결국, 암호경제학적 접근법은 가장 간단하고 쉽고 아마 가장 저렴할 수도 있지만, 가장 매력적이지는 않으며, 원칙적으로 가장 안전하지도 않습니다. 그렇지만 언제나 악마는 세부사항에 있습니다.</p>
<p>예시: Ritual (현재는 미상세), Atoma Network</p>
<h2>왜 검증 가능한 ML은 어려운가요</h2>
<p>왜 우리가 이 모든 것을 갖고 있지 않은지 궁금할 수 있습니다. 결국, 기계학습 모델은 매우 큰 컴퓨터 프로그램에 불과합니다. 프로그램이 올바르게 실행되었다는 것을 증명하는 것은 블록체인의 핵심 역량이었습니다.</p>
<p>여기서 이 세 가지 인증 접근법이 블록체인이 블록 공간을 보호하는 방식과 닮아 있다는 것을 알 수 있습니다. ZK 롤업은 ZK 증명을 사용하고, 낙관롤업은 부정 증명을 사용하며, 대다수의 L1 블록체인은 암호경제학을 사용합니다. 이 같은 해결책에 도달한 것은 놀라운 일이 아닐 것입니다. 그렇다면 ML에 이를 적용할 때 왜 어려울까요?</p>
<p>ML은 ML 계산이 일반적으로 GPU에서 효율적으로 실행되도록 설계된 조밀한 계산 그래프로 표현된다는 점에서 독특합니다. 이러한 계산은 증명될 목적으로 설계되지 않았습니다. 그러므로 ZK 또는 낙관적 환경에서 ML 계산을 증명하려면 가능하게 만들기 위해 재컴파일해야 합니다. 이는 매우 복잡하고 비용이 많이 듭니다.</p>
<p>ML의 두 번째 기본적인 어려움은 비결정론성입니다. 프로그램 검증은 프로그램의 출력이 결정론적이라고 가정합니다. 그러나 같은 모델을 서로 다른 GPU 아키텍처나 CUDA 버전에서 실행하면 다른 출력을 얻을 수 있습니다. 심지어 각 노드가 동일한 아키텍처를 사용하도록 강제하더라도 알고리즘에서 사용하는 무작위성 문제(확산 모형의 노이즈 또는 LLM에서 토큰 샘플링)가 있습니다. RNG 시드를 제어함으로써 그 무작위성을 고칠 수 있습니다. 그렇지만 실수 연산에 내재된 비결정론성 문제는 남아 있습니다.</p>
<p>거의 모든 GPU에서 수행되는 작업은 부동 소수점 숫자입니다. 부동 소수점은 연산이 관련이 없기 때문에 까다로운데요 - 즉, 부동 소수점에 대해 항상 (a + b) + c가 a + (b + c)와 항상 같다고 할 수 없습니다. GPU가 고도로 병렬화되어 있기 때문에 각 실행마다 덧셈이나 곱셈의 순서가 다를 수 있으며, 이는 출력에 작은 차이로 이어질 수 있습니다. 이는 단어의 이산적인 성격으로 인해 LLM의 출력에 영향을 미칠 가능성이 적지만, 이미지 모델의 경우 서로 다른 픽셀 값으로 이어져서 두 이미지가 완벽하게 일치하지 않을 수 있습니다.</p>
<p>이는 부동 소수점을 사용하는 것을 피해야 하거나 성능에 막대한 타격을 입히는 것을 의미하므로, 출력을 비교할 때 일정한 여유를 줘야 합니다. 어쨌든, 세부 사항은 까다롭고, 그것들을 완전히 추상화할 수 없습니다. (그래서, 사실 EVM은 부동 소수점 수를 지원하지 않는 것으로 나타났는데, NEAR와 같은 일부 블록체인은 지원합니다.)</p>
<p>요약하면, 분산된 추론 네트워크는 세부 사항이 중요하기 때문에 어려운데, 현실에는 놀라울정도로 많은 세부 사항이 포함되어 있습니다.</p>
<h2>결론</h2>
<p>지금 블록체인과 머신 러닝은 분명히 많은 이야기를 나눌만한 가치가 있습니다. 하나는 신뢰를 만들어내는 기술이며, 다른 하나는 그 신뢰가 절실히 필요한 기술입니다. 탈중앙화 추론에 대한 각 접근 방식은 각자의 희생을 가지고 있지만, 저는 기업가들이 이러한 도구들을 활용하여 최고의 네트워크를 구축하는 과정에 매우 흥미를 느낍니다.</p>
<p>하지만 이 글은 최종 결론을 내리기 위해 쓴 것이 아닙니다. 실시간으로 이러한 아이디어에 대해 많이 생각하고 사람들과 활발한 논의를 나누고 있습니다. 언제나 아이디어를 테스트하는 가장 좋은 방법은 글을 쓰는 것으로 생각해요. 이 분야에서 무언가를 구축 중이라면 연락해주세요! 당신이 작업 중인 것을 배우는 것에 항상 흥미를 느낄 것이며, 만일 당신이 제가 틀렸다는 것을 증명해준다면 더할 나위 없이 좋겠습니다.</p>
<p>본 기사는 저자의 주관적 의견을 대표하며, Dragonfly나 해당 계열사의 의견이 아닙니다. Dragonfly가 관리하는 자금은 본문에서 언급된 프로토콜 및 암호화폐 중 일부에 투자할 수 있습니다. 본 기사는 투자 조언이 아니며, 어떠한 투자의 근거로 사용되어서도 안 되며 어떠한 투자의 가치를 평가하는 데도 의존해서는 안 됩니다.</p>
<p>Illia Polosukhin, Casey Karuso, Sreeram Kannan, 그리고 Cheryl Chan에게 이 글의 초안을 검토해 준 것에 감사드립니다.</p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"신뢰하지 말고 검증하세요 탈중앙화 추론 개요","description":"","date":"2024-05-05 16:28","slug":"2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference","content":"\n\nLlama2-70B와 같은 대규모 언어 모델을 실행하려고 한다고 가정해 봅시다. 이 정도 규모의 모델을 실행하려면 140GB 이상의 메모리가 필요합니다. 이는 집에 있는 컴퓨터에서 원시 모델을 실행할 수 없다는 것을 의미합니다. 그렇다면 옵션은 무엇일까요? 클라우드 제공업체로 이동할 수 있지만, 이 작업 부하를 처리하고 사용 데이터를 모아가는 단일 중앙화된 회사에 너무 의존하기를 원치 않을 수도 있습니다. 그럴 때 필요한 것은 분산 추론(decentralized inference)입니다. 이것을 통해 단일 공급업체에 의존하지 않고 ML 모델을 실행할 수 있습니다.\n\n## 신뢰 문제\n\n분산 네트워크에서 모델을 실행하고 출력을 신뢰한다는 것만으로는 충분하지 않습니다. 예를 들어 네트워크에게 Llama2-70B를 사용하여 거버넌스 딜레마를 분석해 달라고 요청했다고 가정해 봅시다. 어떻게 알 수 있을까요? 실제로 Llama2-13B를 사용하여 더 나쁜 분석을 제공하고 그 차이를 얻고 있는 것은 아닌지요?\n\n중앙화된 세계에서는 OpenAI와 같은 기업들이 실질적인 미션 수행 때문에 정직하게 일처리를 한다고 믿을지도 모릅니다(그리고 어느 정도로는 LLM 품질이 명백합니다). 그러나 분산화된 세계에서는 정직함이 가정되지 않습니다 — 검증되어야 합니다.\n\n\n\n이곳이 검증 가능 추론의 중요성이 드러나는 곳입니다. 질문에 대한 응답을 제공하는 것뿐만 아니라 요청한 모델에서 정확히 실행되었음을 증명해야 합니다. 하지만 어떻게 할까요?\n\n소박한 방식은 모델을 스마트 계약으로 체인 상에서 실행하는 것일 것입니다. 이렇게 하면 출력이 검증되었음이 보장될 것입니다. 하지만 이는 현실적으로 매우 어렵습니다. GPT-3는 12,288 차원의 임베딩으로 단어를 표현합니다. 이 크기의 단일 행렬 곱셈을 체인 상에서 수행하려면, 현재의 가스 가격에서는 약 100억 달러가 들 것입니다. 계산이 각 블록을 한 달 동안 가득 채울 것입니다.\n\n그러므로, 아닙니다. 우리는 다른 방법이 필요할 것입니다.\n\n현 상황을 분석한 결과, 검증 가능 추론을 다루기 위해 등장한 세 가지 주요 방법이 있다는 것이 분명합니다: 제로 지식 증명, 낙관적 사기 증명, 그리고 암호경제학입니다. 각각이 강도와 비용 측면에서 독특한 특성을 지니고 있습니다.\n\n\n\n![Zero-Knowledge Proofs (ZK ML)](./assets/img/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference_0.png)\n\n## 1. Zero-Knowledge Proofs (ZK ML)\n\n지금부터 상상해보세요. 여러분이 대규모 모델을 실행했다는 것을 증명할 수 있는데, 그 증명이 모델의 크기에 관계없이 고정 크기로 유효하다고 말이죠. 바로 ZK ML이 약속하는 것입니다. ZK-SNARKs의 마법 속에요.\n\n이론적으로 훌륭해 보이긴 하지만, 딥 뉴럴 네트워크를 제로-지식 회로로 컴파일하고, 이를 증명할 수 있는 것은 굉장히 어려운 일이에요. 게다가 이는 엄청난 비용을 초래합니다. 최소한 추론 비용 및 생성된 증명에 드는 시간(지연)이 1000배 이상 증가할 것으로 보입니다. 여기에다가 이 모든 일이 발생하기 전에 모델 자체를 회로로 컴파일해야 하는 점도 빼놓을 수 없죠. 결과적으로 이러한 비용은 사용자에게 전가되어, 최종 사용자에게는 매우 비싸게 들어갈 것으로 예상됩니다.\n\n\n\n그 반면, 이것은 암호학적으로 정확성을 보장하는 유일한 방법입니다. ZK를 사용하면, 모델 제공자가 어떻게 노력해도 속이기가 불가능합니다. 그러나 이 방법은 막대한 비용이 들어가기 때문에 장래에 거대한 모델에 대해 비실용적입니다.\n\n예시: EZKL, 모듈러스 랩스, 기자\n\n## 2. 낙관적 사기 증명 (낙관적 ML)\n\n낙관적인 접근법은 믿음을 가지고 확인하는 것입니다. 추론이 올바르다고 가정하고, 그렇지 않음이 증명될 때까지 기다립니다. 노드가 속이려고 시도하면, 네트워크 내의 \"감시자\"들이 그를 발각하고 사기를 증명하는 증인을 동원할 수 있습니다. 이러한 감시자들은 항상 체인을 감시하고 자신의 모델에서 다시 추론을 실행하여 결과가 올바른지 확인해야 합니다.\n\n\n\n이러한 사기 증명은 Truebit 스타일의 대화형 도전-응답 게임으로, 모델 실행 추적을 체인 상에서 반복적으로 이등분하여 오류를 찾을 때까지 진행됩니다.\n\n![image](https://www.example.com/assets/img/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference_1.png)\n\n이것이 실제로 발생하면 매우 비용이 많이 듭니다. 왜냐하면 이러한 프로그램은 거대하며 엄청난 내부 상태를 가지고 있기 때문입니다. 단일 GPT-3 추론 비용은 약 1 페타플롭(10의 15제곱 부동 소수점 연산)입니다. 그러나 게임 이론은 이러한 사건이 거의 발생하지 않아야 한다고 제안합니다. (사기 증명이 프로그램 코드가 실제 운영 중에 거의 절대 호출되지 않기 때문에 코드 작성이 매우 어렵습니다.)\n\n이점은 낙관적인 기계 학습이 적어도 주시하는 한 사안 안전하다는 것입니다. 비용은 ZK 기계 학습보다 저렴하지만, 네트워크의 각 관찰자가 각 조회를 다시 실행하고 있다는 것을 명심하십시오. 평형상태에서, 10명의 관찰자가 있다면 해당 보안 비용은 사용자에게 전가되어야 하기 때문에 사용자는 추론 비용의 10배 이상(또는 관찰자 수에 따라 다름)을 지불해야 합니다.\n\n\n\n아래로스가 놀라운 롤업들과 같이, 답변이 확인되는 데 도전 기간이 지나야 확실해진다는 단점이 있습니다. 그러나 네트워크 매개변수가 어떻게 설정되어 있는지에 따라, 몇 분만 기다리면 되는 경우도 있습니다.\n\n예시: Ora, Gensyn (현재는 미상세)\n\n## 3. Cryptoeconomics (암호 경제학 머신러닝)\n\n여기서 우리는 모든 멋진 기술을 버리고 간단한 방법을 사용합니다: 지분 가중 투표. 사용자가 쿼리를 실행할 노드 수를 결정하고, 각 노드가 응답을 공개하고, 응답들 사이에 불일치가 있으면 이상한 것이 벌칙을 받습니다. 표준 오라클 내용이며, 사용자가 원하는 보안 수준을 설정하여 비용과 신뢰를 균형있게 조절할 수 있는 더 직접적인 접근 방식입니다. Chainlink가 머신러닝을 수행한다면 이렇게 할 것입니다.\n\n\n\n여기서의 대기 시간은 빠릅니다. 각 노드에서 commit-reveal 만 있으면 됩니다. 이것이 블록체인에 기록되어야 한다면, 기술적으로 이 작업은 두 개의 블록 안에 처리될 수 있습니다.\n\n하지만 보안은 가장 취약합니다. 대부분의 노드들이 마치 충분히 교묘해진다면 의도적으로 공모할 수 있습니다. 사용자로서, 여러분은 이 노드들이 얼마나 많은 것을 잃을 지, 그리고 부정행위를 한다면 그 비용이 얼마나 나갈 지에 대해 고려해야 합니다. 그럼에도 불구하고, Eigenlayer 재입금 및 연결 가능한 보안과 같은 것을 사용하면, 네트워크는 사실상 보안 실패의 경우에 보험을 제공할 수 있습니다.\n\n하지만 이 시스템의 좋은 점은 사용자가 얼마나 많은 보안을 원하는지를 지정할 수 있다는 것입니다. 그들은 자신의 쿼럼에 3개 또는 5개의 노드를 선택하거나 네트워크의 모든 노드를 선택할 수 있습니다. 혹은 YOLO를 하길 원한다면, n=1을 선택할 수도 있습니다. 여기서의 비용 함수는 간단합니다: 사용자는 자신의 쿼럼에 얼마나 많은 노드를 원하는 지에 대해 지불합니다. 3개를 선택하면, 추론 비용의 3배를 지불합니다.\n\n여기서의 까다로운 질문은, n=1을 안전하게 만들 수 있을까요? 단순 구현에서는, 한 개의 노드는 누가 확인하지 않는 한 항상 부정행위를 할 것입니다. 하지만 쿼리를 암호화하고 의도를 통해 지불하면, 이 작업에 대한 유일한 응답자가 실제로 자신인 것으로 노드에게 혼동을 줄 수 있을 것입니다. 이 경우, 일반 사용자들에게 평균 추론 비용의 2배 이하를 청구할 수도 있을 것입니다.\n\n\n\n결국, 암호경제학적 접근법은 가장 간단하고 쉽고 아마 가장 저렴할 수도 있지만, 가장 매력적이지는 않으며, 원칙적으로 가장 안전하지도 않습니다. 그렇지만 언제나 악마는 세부사항에 있습니다.\n\n예시: Ritual (현재는 미상세), Atoma Network\n\n## 왜 검증 가능한 ML은 어려운가요\n\n왜 우리가 이 모든 것을 갖고 있지 않은지 궁금할 수 있습니다. 결국, 기계학습 모델은 매우 큰 컴퓨터 프로그램에 불과합니다. 프로그램이 올바르게 실행되었다는 것을 증명하는 것은 블록체인의 핵심 역량이었습니다.\n\n\n\n여기서 이 세 가지 인증 접근법이 블록체인이 블록 공간을 보호하는 방식과 닮아 있다는 것을 알 수 있습니다. ZK 롤업은 ZK 증명을 사용하고, 낙관롤업은 부정 증명을 사용하며, 대다수의 L1 블록체인은 암호경제학을 사용합니다. 이 같은 해결책에 도달한 것은 놀라운 일이 아닐 것입니다. 그렇다면 ML에 이를 적용할 때 왜 어려울까요?\n\nML은 ML 계산이 일반적으로 GPU에서 효율적으로 실행되도록 설계된 조밀한 계산 그래프로 표현된다는 점에서 독특합니다. 이러한 계산은 증명될 목적으로 설계되지 않았습니다. 그러므로 ZK 또는 낙관적 환경에서 ML 계산을 증명하려면 가능하게 만들기 위해 재컴파일해야 합니다. 이는 매우 복잡하고 비용이 많이 듭니다.\n\nML의 두 번째 기본적인 어려움은 비결정론성입니다. 프로그램 검증은 프로그램의 출력이 결정론적이라고 가정합니다. 그러나 같은 모델을 서로 다른 GPU 아키텍처나 CUDA 버전에서 실행하면 다른 출력을 얻을 수 있습니다. 심지어 각 노드가 동일한 아키텍처를 사용하도록 강제하더라도 알고리즘에서 사용하는 무작위성 문제(확산 모형의 노이즈 또는 LLM에서 토큰 샘플링)가 있습니다. RNG 시드를 제어함으로써 그 무작위성을 고칠 수 있습니다. 그렇지만 실수 연산에 내재된 비결정론성 문제는 남아 있습니다.\n\n\n\n거의 모든 GPU에서 수행되는 작업은 부동 소수점 숫자입니다. 부동 소수점은 연산이 관련이 없기 때문에 까다로운데요 - 즉, 부동 소수점에 대해 항상 (a + b) + c가 a + (b + c)와 항상 같다고 할 수 없습니다. GPU가 고도로 병렬화되어 있기 때문에 각 실행마다 덧셈이나 곱셈의 순서가 다를 수 있으며, 이는 출력에 작은 차이로 이어질 수 있습니다. 이는 단어의 이산적인 성격으로 인해 LLM의 출력에 영향을 미칠 가능성이 적지만, 이미지 모델의 경우 서로 다른 픽셀 값으로 이어져서 두 이미지가 완벽하게 일치하지 않을 수 있습니다.\n\n이는 부동 소수점을 사용하는 것을 피해야 하거나 성능에 막대한 타격을 입히는 것을 의미하므로, 출력을 비교할 때 일정한 여유를 줘야 합니다. 어쨌든, 세부 사항은 까다롭고, 그것들을 완전히 추상화할 수 없습니다. (그래서, 사실 EVM은 부동 소수점 수를 지원하지 않는 것으로 나타났는데, NEAR와 같은 일부 블록체인은 지원합니다.)\n\n요약하면, 분산된 추론 네트워크는 세부 사항이 중요하기 때문에 어려운데, 현실에는 놀라울정도로 많은 세부 사항이 포함되어 있습니다.\n\n## 결론\n\n\n\n지금 블록체인과 머신 러닝은 분명히 많은 이야기를 나눌만한 가치가 있습니다. 하나는 신뢰를 만들어내는 기술이며, 다른 하나는 그 신뢰가 절실히 필요한 기술입니다. 탈중앙화 추론에 대한 각 접근 방식은 각자의 희생을 가지고 있지만, 저는 기업가들이 이러한 도구들을 활용하여 최고의 네트워크를 구축하는 과정에 매우 흥미를 느낍니다.\n\n하지만 이 글은 최종 결론을 내리기 위해 쓴 것이 아닙니다. 실시간으로 이러한 아이디어에 대해 많이 생각하고 사람들과 활발한 논의를 나누고 있습니다. 언제나 아이디어를 테스트하는 가장 좋은 방법은 글을 쓰는 것으로 생각해요. 이 분야에서 무언가를 구축 중이라면 연락해주세요! 당신이 작업 중인 것을 배우는 것에 항상 흥미를 느낄 것이며, 만일 당신이 제가 틀렸다는 것을 증명해준다면 더할 나위 없이 좋겠습니다.\n\n본 기사는 저자의 주관적 의견을 대표하며, Dragonfly나 해당 계열사의 의견이 아닙니다. Dragonfly가 관리하는 자금은 본문에서 언급된 프로토콜 및 암호화폐 중 일부에 투자할 수 있습니다. 본 기사는 투자 조언이 아니며, 어떠한 투자의 근거로 사용되어서도 안 되며 어떠한 투자의 가치를 평가하는 데도 의존해서는 안 됩니다.\n\nIllia Polosukhin, Casey Karuso, Sreeram Kannan, 그리고 Cheryl Chan에게 이 글의 초안을 검토해 준 것에 감사드립니다.","ogImage":{"url":"/assets/img/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference_0.png"},"coverImage":"/assets/img/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference_0.png","tag":["Tech"],"readingTime":7},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    h2: \"h2\",\n    img: \"img\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"Llama2-70B와 같은 대규모 언어 모델을 실행하려고 한다고 가정해 봅시다. 이 정도 규모의 모델을 실행하려면 140GB 이상의 메모리가 필요합니다. 이는 집에 있는 컴퓨터에서 원시 모델을 실행할 수 없다는 것을 의미합니다. 그렇다면 옵션은 무엇일까요? 클라우드 제공업체로 이동할 수 있지만, 이 작업 부하를 처리하고 사용 데이터를 모아가는 단일 중앙화된 회사에 너무 의존하기를 원치 않을 수도 있습니다. 그럴 때 필요한 것은 분산 추론(decentralized inference)입니다. 이것을 통해 단일 공급업체에 의존하지 않고 ML 모델을 실행할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"신뢰 문제\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"분산 네트워크에서 모델을 실행하고 출력을 신뢰한다는 것만으로는 충분하지 않습니다. 예를 들어 네트워크에게 Llama2-70B를 사용하여 거버넌스 딜레마를 분석해 달라고 요청했다고 가정해 봅시다. 어떻게 알 수 있을까요? 실제로 Llama2-13B를 사용하여 더 나쁜 분석을 제공하고 그 차이를 얻고 있는 것은 아닌지요?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"중앙화된 세계에서는 OpenAI와 같은 기업들이 실질적인 미션 수행 때문에 정직하게 일처리를 한다고 믿을지도 모릅니다(그리고 어느 정도로는 LLM 품질이 명백합니다). 그러나 분산화된 세계에서는 정직함이 가정되지 않습니다 — 검증되어야 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이곳이 검증 가능 추론의 중요성이 드러나는 곳입니다. 질문에 대한 응답을 제공하는 것뿐만 아니라 요청한 모델에서 정확히 실행되었음을 증명해야 합니다. 하지만 어떻게 할까요?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"소박한 방식은 모델을 스마트 계약으로 체인 상에서 실행하는 것일 것입니다. 이렇게 하면 출력이 검증되었음이 보장될 것입니다. 하지만 이는 현실적으로 매우 어렵습니다. GPT-3는 12,288 차원의 임베딩으로 단어를 표현합니다. 이 크기의 단일 행렬 곱셈을 체인 상에서 수행하려면, 현재의 가스 가격에서는 약 100억 달러가 들 것입니다. 계산이 각 블록을 한 달 동안 가득 채울 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그러므로, 아닙니다. 우리는 다른 방법이 필요할 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"현 상황을 분석한 결과, 검증 가능 추론을 다루기 위해 등장한 세 가지 주요 방법이 있다는 것이 분명합니다: 제로 지식 증명, 낙관적 사기 증명, 그리고 암호경제학입니다. 각각이 강도와 비용 측면에서 독특한 특성을 지니고 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"./assets/img/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference_0.png\",\n        alt: \"Zero-Knowledge Proofs (ZK ML)\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"1. Zero-Knowledge Proofs (ZK ML)\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"지금부터 상상해보세요. 여러분이 대규모 모델을 실행했다는 것을 증명할 수 있는데, 그 증명이 모델의 크기에 관계없이 고정 크기로 유효하다고 말이죠. 바로 ZK ML이 약속하는 것입니다. ZK-SNARKs의 마법 속에요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이론적으로 훌륭해 보이긴 하지만, 딥 뉴럴 네트워크를 제로-지식 회로로 컴파일하고, 이를 증명할 수 있는 것은 굉장히 어려운 일이에요. 게다가 이는 엄청난 비용을 초래합니다. 최소한 추론 비용 및 생성된 증명에 드는 시간(지연)이 1000배 이상 증가할 것으로 보입니다. 여기에다가 이 모든 일이 발생하기 전에 모델 자체를 회로로 컴파일해야 하는 점도 빼놓을 수 없죠. 결과적으로 이러한 비용은 사용자에게 전가되어, 최종 사용자에게는 매우 비싸게 들어갈 것으로 예상됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그 반면, 이것은 암호학적으로 정확성을 보장하는 유일한 방법입니다. ZK를 사용하면, 모델 제공자가 어떻게 노력해도 속이기가 불가능합니다. 그러나 이 방법은 막대한 비용이 들어가기 때문에 장래에 거대한 모델에 대해 비실용적입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"예시: EZKL, 모듈러스 랩스, 기자\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"2. 낙관적 사기 증명 (낙관적 ML)\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"낙관적인 접근법은 믿음을 가지고 확인하는 것입니다. 추론이 올바르다고 가정하고, 그렇지 않음이 증명될 때까지 기다립니다. 노드가 속이려고 시도하면, 네트워크 내의 \\\"감시자\\\"들이 그를 발각하고 사기를 증명하는 증인을 동원할 수 있습니다. 이러한 감시자들은 항상 체인을 감시하고 자신의 모델에서 다시 추론을 실행하여 결과가 올바른지 확인해야 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이러한 사기 증명은 Truebit 스타일의 대화형 도전-응답 게임으로, 모델 실행 추적을 체인 상에서 반복적으로 이등분하여 오류를 찾을 때까지 진행됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://www.example.com/assets/img/2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference_1.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이것이 실제로 발생하면 매우 비용이 많이 듭니다. 왜냐하면 이러한 프로그램은 거대하며 엄청난 내부 상태를 가지고 있기 때문입니다. 단일 GPT-3 추론 비용은 약 1 페타플롭(10의 15제곱 부동 소수점 연산)입니다. 그러나 게임 이론은 이러한 사건이 거의 발생하지 않아야 한다고 제안합니다. (사기 증명이 프로그램 코드가 실제 운영 중에 거의 절대 호출되지 않기 때문에 코드 작성이 매우 어렵습니다.)\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이점은 낙관적인 기계 학습이 적어도 주시하는 한 사안 안전하다는 것입니다. 비용은 ZK 기계 학습보다 저렴하지만, 네트워크의 각 관찰자가 각 조회를 다시 실행하고 있다는 것을 명심하십시오. 평형상태에서, 10명의 관찰자가 있다면 해당 보안 비용은 사용자에게 전가되어야 하기 때문에 사용자는 추론 비용의 10배 이상(또는 관찰자 수에 따라 다름)을 지불해야 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"아래로스가 놀라운 롤업들과 같이, 답변이 확인되는 데 도전 기간이 지나야 확실해진다는 단점이 있습니다. 그러나 네트워크 매개변수가 어떻게 설정되어 있는지에 따라, 몇 분만 기다리면 되는 경우도 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"예시: Ora, Gensyn (현재는 미상세)\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"3. Cryptoeconomics (암호 경제학 머신러닝)\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"여기서 우리는 모든 멋진 기술을 버리고 간단한 방법을 사용합니다: 지분 가중 투표. 사용자가 쿼리를 실행할 노드 수를 결정하고, 각 노드가 응답을 공개하고, 응답들 사이에 불일치가 있으면 이상한 것이 벌칙을 받습니다. 표준 오라클 내용이며, 사용자가 원하는 보안 수준을 설정하여 비용과 신뢰를 균형있게 조절할 수 있는 더 직접적인 접근 방식입니다. Chainlink가 머신러닝을 수행한다면 이렇게 할 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"여기서의 대기 시간은 빠릅니다. 각 노드에서 commit-reveal 만 있으면 됩니다. 이것이 블록체인에 기록되어야 한다면, 기술적으로 이 작업은 두 개의 블록 안에 처리될 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"하지만 보안은 가장 취약합니다. 대부분의 노드들이 마치 충분히 교묘해진다면 의도적으로 공모할 수 있습니다. 사용자로서, 여러분은 이 노드들이 얼마나 많은 것을 잃을 지, 그리고 부정행위를 한다면 그 비용이 얼마나 나갈 지에 대해 고려해야 합니다. 그럼에도 불구하고, Eigenlayer 재입금 및 연결 가능한 보안과 같은 것을 사용하면, 네트워크는 사실상 보안 실패의 경우에 보험을 제공할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"하지만 이 시스템의 좋은 점은 사용자가 얼마나 많은 보안을 원하는지를 지정할 수 있다는 것입니다. 그들은 자신의 쿼럼에 3개 또는 5개의 노드를 선택하거나 네트워크의 모든 노드를 선택할 수 있습니다. 혹은 YOLO를 하길 원한다면, n=1을 선택할 수도 있습니다. 여기서의 비용 함수는 간단합니다: 사용자는 자신의 쿼럼에 얼마나 많은 노드를 원하는 지에 대해 지불합니다. 3개를 선택하면, 추론 비용의 3배를 지불합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"여기서의 까다로운 질문은, n=1을 안전하게 만들 수 있을까요? 단순 구현에서는, 한 개의 노드는 누가 확인하지 않는 한 항상 부정행위를 할 것입니다. 하지만 쿼리를 암호화하고 의도를 통해 지불하면, 이 작업에 대한 유일한 응답자가 실제로 자신인 것으로 노드에게 혼동을 줄 수 있을 것입니다. 이 경우, 일반 사용자들에게 평균 추론 비용의 2배 이하를 청구할 수도 있을 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"결국, 암호경제학적 접근법은 가장 간단하고 쉽고 아마 가장 저렴할 수도 있지만, 가장 매력적이지는 않으며, 원칙적으로 가장 안전하지도 않습니다. 그렇지만 언제나 악마는 세부사항에 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"예시: Ritual (현재는 미상세), Atoma Network\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"왜 검증 가능한 ML은 어려운가요\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"왜 우리가 이 모든 것을 갖고 있지 않은지 궁금할 수 있습니다. 결국, 기계학습 모델은 매우 큰 컴퓨터 프로그램에 불과합니다. 프로그램이 올바르게 실행되었다는 것을 증명하는 것은 블록체인의 핵심 역량이었습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"여기서 이 세 가지 인증 접근법이 블록체인이 블록 공간을 보호하는 방식과 닮아 있다는 것을 알 수 있습니다. ZK 롤업은 ZK 증명을 사용하고, 낙관롤업은 부정 증명을 사용하며, 대다수의 L1 블록체인은 암호경제학을 사용합니다. 이 같은 해결책에 도달한 것은 놀라운 일이 아닐 것입니다. 그렇다면 ML에 이를 적용할 때 왜 어려울까요?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"ML은 ML 계산이 일반적으로 GPU에서 효율적으로 실행되도록 설계된 조밀한 계산 그래프로 표현된다는 점에서 독특합니다. 이러한 계산은 증명될 목적으로 설계되지 않았습니다. 그러므로 ZK 또는 낙관적 환경에서 ML 계산을 증명하려면 가능하게 만들기 위해 재컴파일해야 합니다. 이는 매우 복잡하고 비용이 많이 듭니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"ML의 두 번째 기본적인 어려움은 비결정론성입니다. 프로그램 검증은 프로그램의 출력이 결정론적이라고 가정합니다. 그러나 같은 모델을 서로 다른 GPU 아키텍처나 CUDA 버전에서 실행하면 다른 출력을 얻을 수 있습니다. 심지어 각 노드가 동일한 아키텍처를 사용하도록 강제하더라도 알고리즘에서 사용하는 무작위성 문제(확산 모형의 노이즈 또는 LLM에서 토큰 샘플링)가 있습니다. RNG 시드를 제어함으로써 그 무작위성을 고칠 수 있습니다. 그렇지만 실수 연산에 내재된 비결정론성 문제는 남아 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"거의 모든 GPU에서 수행되는 작업은 부동 소수점 숫자입니다. 부동 소수점은 연산이 관련이 없기 때문에 까다로운데요 - 즉, 부동 소수점에 대해 항상 (a + b) + c가 a + (b + c)와 항상 같다고 할 수 없습니다. GPU가 고도로 병렬화되어 있기 때문에 각 실행마다 덧셈이나 곱셈의 순서가 다를 수 있으며, 이는 출력에 작은 차이로 이어질 수 있습니다. 이는 단어의 이산적인 성격으로 인해 LLM의 출력에 영향을 미칠 가능성이 적지만, 이미지 모델의 경우 서로 다른 픽셀 값으로 이어져서 두 이미지가 완벽하게 일치하지 않을 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이는 부동 소수점을 사용하는 것을 피해야 하거나 성능에 막대한 타격을 입히는 것을 의미하므로, 출력을 비교할 때 일정한 여유를 줘야 합니다. 어쨌든, 세부 사항은 까다롭고, 그것들을 완전히 추상화할 수 없습니다. (그래서, 사실 EVM은 부동 소수점 수를 지원하지 않는 것으로 나타났는데, NEAR와 같은 일부 블록체인은 지원합니다.)\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"요약하면, 분산된 추론 네트워크는 세부 사항이 중요하기 때문에 어려운데, 현실에는 놀라울정도로 많은 세부 사항이 포함되어 있습니다.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"결론\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"지금 블록체인과 머신 러닝은 분명히 많은 이야기를 나눌만한 가치가 있습니다. 하나는 신뢰를 만들어내는 기술이며, 다른 하나는 그 신뢰가 절실히 필요한 기술입니다. 탈중앙화 추론에 대한 각 접근 방식은 각자의 희생을 가지고 있지만, 저는 기업가들이 이러한 도구들을 활용하여 최고의 네트워크를 구축하는 과정에 매우 흥미를 느낍니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"하지만 이 글은 최종 결론을 내리기 위해 쓴 것이 아닙니다. 실시간으로 이러한 아이디어에 대해 많이 생각하고 사람들과 활발한 논의를 나누고 있습니다. 언제나 아이디어를 테스트하는 가장 좋은 방법은 글을 쓰는 것으로 생각해요. 이 분야에서 무언가를 구축 중이라면 연락해주세요! 당신이 작업 중인 것을 배우는 것에 항상 흥미를 느낄 것이며, 만일 당신이 제가 틀렸다는 것을 증명해준다면 더할 나위 없이 좋겠습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"본 기사는 저자의 주관적 의견을 대표하며, Dragonfly나 해당 계열사의 의견이 아닙니다. Dragonfly가 관리하는 자금은 본문에서 언급된 프로토콜 및 암호화폐 중 일부에 투자할 수 있습니다. 본 기사는 투자 조언이 아니며, 어떠한 투자의 근거로 사용되어서도 안 되며 어떠한 투자의 가치를 평가하는 데도 의존해서는 안 됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Illia Polosukhin, Casey Karuso, Sreeram Kannan, 그리고 Cheryl Chan에게 이 글의 초안을 검토해 준 것에 감사드립니다.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-05-DontTrustVerifyAnOverviewofDecentralizedInference"},"buildId":"o88Ur64-oLrud7YPysgph","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>